# Web Application Scanning (burp, nikto, etc.)
# - look at urls (identify stack)
# - inspect page content
# - inspect response headers
# - inspect sitemaps (`sitemap.xml`, `robots.txt`)
# - locate admin consoles (ie. `/phpmyadmin`, `/manager/html`)
# - break out the automated scanners
#   - wordlists to find directories and pages (ie. DIRB)
#
# OWASP top 10 vulnerabilities also give us an idea of things to try:
# - XSS (stored, reflected)
# - session/cookie stealing
# - directory traversal (ie. inserting ../ into path to escape web dir)
# - content injection (ie. redirect target to attacker)
# - file inclusion (ie. uploading reverse shell w/ dif file ext)
# - sql injection

# Read all of: https://owasp.org/www-community/vulnerabilities/

# nikto - fingerpent, vulns, risky config, paths
Nikto -h https://192.168.1.48
# gobuster - paths only
Gobuster -u 192.168.1.48 -w /usr/share/seclists/Discovery/Web/common.txt

# wfuzz - test for SQLi
wfuzz -c -z file,/usr/share/wfuzz/wordlist/Injections/SQL.txt --hh 667 -d "uname=adminMARIA&psw=FUZZ&btnLogin=Login" http://192.168.1.48/index.php

# wfuzz - test for LFI (ie. path traversal + file read)
wfuzz -c -z file,/usr/share/wfuzz/wordlist/Injections/All_attack.txt http://kioptrix3.com/index.php?system=FUZZ

# wfuzz - subdomain guessing (ie. if you find default IIS or Apache pages)
wfuzz -c -w /usr/share/seclists/Discovery/DNS/bitquark-subdomains-top100000.txt -u http://10.10.10.203 -H 'Host: FUZZ.worker.htb' --hh 703


# ffuf - golang Fuzz Faster U Fool (can fuzz directories, http verbs, many things)
PATH=/usr/local/go/bin:$PATH
go get -u github.com/ffuf/ffuf
PATH=~/go/bin:$PATH
ffuf # v1.3.1-dev
cd /usr/share/seclists/
# flat scan of subdirectory
ffuf -u https://1.2.3.4/FUZZ/ -w wordlist.txt 
# each discovery will lead it to prefix the found part with /FUZZ part and keep going deeper
ffuf -u https://1.2.3.4/FUZZ/ -w wordlist.txt --recursion
# will append guesses with the extension ie. FUZZ.bak => admin.bak ... zookeeper.bak
ffuf -u https://1.2.3.4/FUZZ/ -w wordlist.txt --recursion -e .bak
# combining multiple wordlists strategically (ie. fuzzing contextually)
ffuf -u https://1.2.3.4/W1/ -w wordlist.txt:W1 --recursion -e .bak
# see help. can fuzz headers, supply cookies, etc.
# can use burp as proxy (to record/debug request history, and leverage its cookie jar etc.)
#   you can even use --replay-proxy which will only send success requests to burp
# you can also provide an entire http raw request.txt with FUZZ keywords if its easier than cli opts
# can control speed (`-p 2`, `-rate 2`) and detect blocks (`-se` or `-sf`)
# auto filtering `-ac` and `-acc` so you deliberately get a fail response and then it remembers it as the negative example to avoid, based on percentage match scoring rather than exact match

# cewl - scraping page to make user list
$ cewl www.megacorpone.com -m 6 -w megacorp-cewl.txt
$ cewl <wikipedia url> -d 0 -w userList
